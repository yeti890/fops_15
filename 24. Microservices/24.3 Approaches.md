# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.
### Ответ:
Для реализации CI/CD процесса предлагаю использовать следующую схему:  

**GitLab → TeamCity → Docker Registry → Kubernetes**

Такой подход сочетает в себе мощные инструменты для версионного контроля, автоматизации сборок и развертывания.  

### **Обоснование выбора:**  

1. **Хранение исходного кода**  
   - В качестве системы контроля версий используется **GitLab**, который обеспечивает удобное управление репозиториями и поддерживает Git.  
   - Можно создать отдельный репозиторий на каждый сервис.  

2. **Автоматическая и ручная сборка**  
   - **TeamCity** выполняет роль CI/CD-сервера, обрабатывая события из GitLab.  
   - Автоматический запуск сборки происходит при коммите или тегировании.  
   - Возможен запуск сборки вручную с указанием параметров.  

3. **Гибкость конфигурации сборок**  
   - TeamCity позволяет задавать **переменные окружения** для каждой сборки.  
   - Поддерживаются шаблоны для различных конфигураций сборок.  
   - Возможно создание нескольких конфигураций для одного репозитория (например, для разных сред: dev, staging, production).  

4. **Безопасность и управление секретами**  
   - Все пароли и ключи доступа можно хранить в **HashiCorp Vault** или в встроенном механизме TeamCity.  
   - Это обеспечивает надежную защиту чувствительных данных.  

5. **Работа с контейнерами**  
   - Docker-образы собираются и загружаются в **Docker Registry** (можно использовать **GitLab Container Registry, Nexus или Harbor**).  
   - Для выполнения сборок можно использовать кастомные Docker-образы.  

6. **Развертывание и масштабирование**  
   - Kubernetes управляет контейнерами, обеспечивая отказоустойчивость и масштабируемость.  
   - CI/CD процесс завершает деплой в кластер Kubernetes после успешной сборки.  

7. **Производительность и масштабируемость**  
   - TeamCity поддерживает **развертывание агентов сборки на собственных серверах**, что позволяет оптимизировать нагрузку.  
   - Можно запускать **параллельные сборки** и **одновременные тесты**.  
  
Такой подход обеспечивает гибкость, масштабируемость и надежность всего процесса CI/CD.  

---

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.
### Ответ:
Для централизованного сбора и анализа логов в микросервисной архитектуре можно использовать **ELK-стек (Elasticsearch, Logstash, Kibana) + Filebeat**.  

### **Обоснование выбора:**  

1. **Сбор логов со всех хостов**  
   - **Filebeat** — легковесный агент для сбора логов с серверов, контейнеров и stdout.  
   - Поддерживает различные источники логов и их маршрутизацию.  

2. **Гарантированная доставка логов**  
   - Filebeat использует буферизацию и повторные попытки отправки при сбоях.  
   - Logstash поддерживает механизмы отказоустойчивости при обработке данных.  

3. **Централизованное хранение и быстрый поиск**  
   - **Elasticsearch** — мощная поисковая база данных, позволяющая хранить, индексировать и анализировать логи.  
   - Поддерживает распределенное хранение данных, горизонтальное масштабирование и репликацию.  

4. **Пользовательский интерфейс и анализ логов**  
   - **Kibana** предоставляет удобный веб-интерфейс для поиска, визуализации и анализа логов.  
   - Поддерживает сохранение поисковых запросов и создание дашбордов.  

5. **Минимальные требования к приложениям**  
   - Приложения пишут логи в stdout, Filebeat забирает их и отправляет в Logstash/Elasticsearch.  
   - Не требуется модификация кода приложений.  

6. **Поддержка сохраненных поисков и ссылок**  
   - Kibana позволяет сохранять запросы и предоставлять ссылки на результаты поиска.  
   - Можно настраивать ролевой доступ для разработчиков.  

### **Принципы взаимодействия компонентов:**  

1. Приложения пишут логи в stdout.  
2. **Filebeat** собирает логи и отправляет их в **Logstash**.  
3. **Logstash** выполняет фильтрацию, нормализацию и отправляет обработанные логи в **Elasticsearch**.  
4. **Elasticsearch** индексирует и хранит логи.  
5. **Kibana** предоставляет интерфейс для поиска, фильтрации и визуализации логов.  
6. Разработчики могут анализировать логи, сохранять запросы и делиться ссылками.  
 
**ELK-стек** — популярное, стабильное и хорошо документированное решение, широко используемое в продакшене.  
Оно отвечает всем требованиям задачи, поддерживает масштабируемость и легко интегрируется с  другими инструментами.

---

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

### Ответ:
Для сбора и анализа метрик предлагаю использовать **стек Prometheus + Grafana**.  
Эта комбинация обеспечивает полный контроль за состоянием хостов и сервисов, а также предоставляет гибкие возможности визуализации.  

### **Компоненты решения:**  

1. **Prometheus**  
   - Система мониторинга и оповещений с открытым исходным кодом.  
   - Использует pull-модель сбора метрик.  
   - Обладает мощным языком запросов **PromQL**.  

2. **Node Exporter**  
   - Экспортер системных метрик (CPU, RAM, HDD, сеть).  
   - Запускается на каждом хосте и передает данные Prometheus.  

3. **cAdvisor**  
   - Инструмент для сбора метрик контейнеров.  
   - Показывает потребление CPU, RAM, дискового пространства и сетевого трафика.  

4. **Grafana**  
   - Мощный инструмент визуализации данных.  
   - Поддерживает кастомные дашборды, фильтры и алерты.  

### **Способы и принципы взаимодействия компонентов:**  

1. **Сбор метрик**  
   - **Node Exporter** собирает метрики системных ресурсов хоста.  
   - **cAdvisor** анализирует потребление ресурсов контейнерами.  
   - Prometheus периодически опрашивает экспортеры и сохраняет данные в базу.  

2. **Мониторинг и визуализация**  
   - Grafana подключается к Prometheus и отображает метрики в виде графиков и панелей.  
   - Пользователи могут кастомизировать дашборды и агрегировать данные.  

3. **Оповещения**  
   - Prometheus поддерживает **Alertmanager**, позволяющий отправлять уведомления при проблемах.  

### **Преимущества решения:**  

| Требование                                                                                                | Функционал Prometheus + Grafana                                                                                                                                                 |
|-----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Сбор метрик со всех хостов, обслуживающих систему                                                         | Поддерживается неограниченное количество хостов для мониторинга                                                                                                                 |
| Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network                                             | Реализуется с помощью **Node Exporter**                                                                                                                                         |
| Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network                             | Реализуется с помощью **cAdvisor** для контейнеров и специализированных экспортеров для сервисов                                                                                |
| Сбор метрик, специфичных для каждого сервиса                                                              | Возможность добавления пользовательских метрик с помощью библиотек Prometheus для различных языков программирования                                                             |
| Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию                        | Поддерживается мощный язык запросов **PromQL**, позволяющий анализировать и агрегировать данные                                                                                |
| Пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы | **Grafana** предоставляет мощные инструменты для визуализации, кастомизации дашбордов и создания сложных аналитических панелей                                                 |

### **Обоснование выбора:**  
- **Широкая поддержка**: Prometheus и Grafana используются во множестве проектов и имеют активное сообщество.  
- **Гибкость**: Возможность интеграции с любыми сервисами через экспортеры.  
- **Масштабируемость**: Поддержка федеративного мониторинга и горизонтального масштабирования.  
- **Низкая нагрузка**: Метод **pull** снижает нагрузку на мониторируемые сервисы.  

Стек **Prometheus + Grafana** полностью отвечает требованиям мониторинга микросервисной архитектуры и обеспечивает надежный сбор, анализ и визуализацию метрик.  

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---